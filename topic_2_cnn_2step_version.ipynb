{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "topic_2_cnn_2step_version.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6cYTDhzbS24",
        "outputId": "6442c6b5-9c78-4918-9418-975204fe9c50"
      },
      "source": [
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "from torchvision import transforms\n",
        "drive.mount(('/content/drive/'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4z1SQOkebZW8"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import tqdm\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzJRnu82bmWu"
      },
      "source": [
        "from glob import glob\n",
        "import pandas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCuiQJyCbogS"
      },
      "source": [
        "device = 'cuda:0'\n",
        "num_joints = 21"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1T4IH6JTbq_z"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = 'cuda:0'\n",
        "\n",
        "\n",
        "# 2d pose estimator - pretrained\n",
        "class CPM2DPose(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CPM2DPose, self).__init__()\n",
        "        \n",
        "        self.scoremap_list = []\n",
        "        self.layers_per_block = [2, 2, 4, 2]\n",
        "        self.out_chan_list = [64, 128, 256, 512]\n",
        "        self.pool_list = [True, True, True, False]\n",
        "\n",
        "        self.relu = F.leaky_relu\n",
        "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=True)  # conv0_1\n",
        "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=True)  # conv0_2\n",
        "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=True)  # conv0_2\n",
        "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=True)  # conv0_2\n",
        "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=True)  # conv0_2\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True)  # conv0_2\n",
        "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True)  # conv0_2\n",
        "        self.conv3_4 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True)  # conv0_2\n",
        "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, bias=True)  # conv0_2\n",
        "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True)  # conv0_2\n",
        "        self.conv4_3 = nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1, bias=True)  # conv0_2\n",
        "        self.conv4_4 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True)  # conv0_2\n",
        "        self.conv4_5 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True)  # conv0_2\n",
        "        self.conv4_6 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True)  # conv0_2\n",
        "        self.conv4_7 = nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1, bias=True)  # conv0_2\n",
        "        self.conv5_1 = nn.Conv2d(128, 512, kernel_size=1, stride=1, padding=0, bias=True)  # conv0_2\n",
        "        self.conv5_2 = nn.Conv2d(512, 21, kernel_size=1, stride=1, padding=0, bias=True)  # conv0_2\n",
        "        self.conv6_1 = nn.Conv2d(149, 128, kernel_size=7, stride=1, padding=3, bias=True)  # conv0_2\n",
        "        self.conv6_2 = nn.Conv2d(128, 128, kernel_size=7, stride=1, padding=3, bias=True)  # conv0_2\n",
        "        self.conv6_3 = nn.Conv2d(128, 128, kernel_size=7, stride=1, padding=3, bias=True)  # conv0_2\n",
        "        self.conv6_4 = nn.Conv2d(128, 128, kernel_size=7, stride=1, padding=3, bias=True)  # conv0_2\n",
        "        self.conv6_5 = nn.Conv2d(128, 128, kernel_size=7, stride=1, padding=3, bias=True)  # conv0_2\n",
        "        self.conv6_6 = nn.Conv2d(128, 128, kernel_size=1, stride=1, padding=0, bias=True)  # conv0_2\n",
        "        self.conv6_7 = nn.Conv2d(128, 21, kernel_size=1, stride=1, padding=0, bias=True)  # conv0_2\n",
        "        self.conv7_1 = nn.Conv2d(149, 128, kernel_size=7, stride=1, padding=3, bias=True)  # conv0_2\n",
        "        self.conv7_2 = nn.Conv2d(128, 128, kernel_size=7, stride=1, padding=3, bias=True)  # conv0_2\n",
        "        self.conv7_3 = nn.Conv2d(128, 128, kernel_size=7, stride=1, padding=3, bias=True)  # conv0_2\n",
        "        self.conv7_4 = nn.Conv2d(128, 128, kernel_size=7, stride=1, padding=3, bias=True)  # conv0_2\n",
        "        self.conv7_5 = nn.Conv2d(128, 128, kernel_size=7, stride=1, padding=3, bias=True)  # conv0_2\n",
        "        self.conv7_6 = nn.Conv2d(128, 128, kernel_size=1, stride=1, padding=0, bias=True)  # conv0_2\n",
        "        self.conv7_7 = nn.Conv2d(128, 21, kernel_size=1, stride=1, padding=0, bias=True)  # conv0_2\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        \n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1_1(x))\n",
        "        x = self.relu(self.conv1_2(x))\n",
        "        x = self.maxpool(x)\n",
        "        x = self.relu(self.conv2_1(x))\n",
        "        x = self.relu(self.conv2_2(x))\n",
        "        x = self.maxpool(x)\n",
        "        x = self.relu(self.conv3_1(x))\n",
        "        x = self.relu(self.conv3_2(x))\n",
        "        x = self.relu(self.conv3_3(x))\n",
        "        x = self.relu(self.conv3_4(x))\n",
        "        x = self.maxpool(x)\n",
        "        x = self.relu(self.conv4_1(x))\n",
        "        x = self.relu(self.conv4_2(x))\n",
        "        x = self.relu(self.conv4_3(x))\n",
        "        x = self.relu(self.conv4_4(x))\n",
        "        x = self.relu(self.conv4_5(x))\n",
        "        x = self.relu(self.conv4_6(x))\n",
        "        encoding = self.relu(self.conv4_7(x))\n",
        "        x = self.relu(self.conv5_1(encoding))\n",
        "        scoremap = self.conv5_2(x)\n",
        "\n",
        "        x = torch.cat([scoremap, encoding], 1)\n",
        "        x = self.relu(self.conv6_1(x))\n",
        "        x = self.relu(self.conv6_2(x))\n",
        "        x = self.relu(self.conv6_3(x))\n",
        "        x = self.relu(self.conv6_4(x))\n",
        "        x = self.relu(self.conv6_5(x))\n",
        "        x = self.relu(self.conv6_6(x))\n",
        "        scoremap = self.conv6_7(x)\n",
        "        x = torch.cat([scoremap, encoding], 1)\n",
        "        x = self.relu(self.conv7_1(x))\n",
        "        x = self.relu(self.conv7_2(x))\n",
        "        x = self.relu(self.conv7_3(x))\n",
        "        x = self.relu(self.conv7_4(x))\n",
        "        x = self.relu(self.conv7_5(x))\n",
        "        x = self.relu(self.conv7_6(x))\n",
        "        x = self.conv7_7(x)\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n8KhmbHkj4T"
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, batch_size):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Linear(21*32*32,256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256,3)\n",
        "        )\n",
        "      \n",
        "    def forward(self, x):\n",
        "        x = x.view(self.batch_size, -1)\n",
        "        x = self.fc_layer(x)\n",
        "        return x\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlrtaX_dbviv"
      },
      "source": [
        "train_img_len = 100\n",
        "test_img_len = 10\n",
        "\n",
        "class HandDataset(Dataset):\n",
        "    def __init__(self, method=None):\n",
        "        self.x_data = []\n",
        "        self.y_data = []\n",
        "        self.z_data = []\n",
        "        self.root = '/content/drive/My Drive/hand_posture_data'\n",
        "        self.weight_root = self.root\n",
        "\n",
        "        if method == 'train':\n",
        "            self.root = self.root + '/train/' # self.root = drive/My Drive/hand_posture_data/train/\n",
        "            rock_path = self.root + 'rock/'\n",
        "            scissors_path = self.root + 'scissors/'\n",
        "            paper_path = self.root + 'paper/'\n",
        "\n",
        "            self.rock_img_path = sorted(glob(rock_path + 'rgb/*.jpg'))\n",
        "            self.scissors_img_path = sorted(glob(scissors_path + 'rgb/*.jpg'))\n",
        "            self.paper_img_path = sorted(glob(paper_path + 'rgb/*.jpg'))\n",
        "\n",
        "            self.img_path = self.rock_img_path + self.scissors_img_path + self.paper_img_path\n",
        "\n",
        "        elif method == 'test':\n",
        "            self.root = self.root + '/test/' # self.root = drive/My Drive/hand_posture_data/test/\n",
        "            rock_path = self.root + 'rock/'\n",
        "            scissors_path = self.root + 'scissors/'\n",
        "            paper_path = self.root + 'paper/'\n",
        "\n",
        "            self.rock_img_path = sorted(glob(rock_path + 'rgb/*.jpg'))\n",
        "            self.scissors_img_path = sorted(glob(scissors_path + 'rgb/*.jpg'))\n",
        "            self.paper_img_path = sorted(glob(paper_path + 'rgb/*.jpg'))\n",
        "\n",
        "            self.img_path = self.rock_img_path + self.scissors_img_path + self.paper_img_path\n",
        "\n",
        "        for i in tqdm.tqdm(range(len(self.img_path))):\n",
        "            img = cv2.imread(self.img_path[i], cv2.IMREAD_COLOR)\n",
        "            #print(self.img_path[i])  \n",
        "            b, g, r = cv2.split(img)\n",
        "            img = cv2.merge([r, g, b])\n",
        "            self.x_data.append(img)\n",
        "\n",
        "            num = self.img_path[i].split('.')[0].split('/')[-1]\n",
        "            \n",
        "            if method == 'train':\n",
        "              if i in range (train_img_len):\n",
        "                img_pkl = self.root + 'rock/meta/' + str(num) + '.pkl'\n",
        "              elif i in range (1*train_img_len, 2*train_img_len):\n",
        "                img_pkl = self.root + 'scissors/meta/' + str(num) + '.pkl'\n",
        "              elif i in range(2*train_img_len, 3*train_img_len):\n",
        "                img_pkl = self.root + 'paper/meta/' + str(num) + '.pkl'\n",
        "\n",
        "            elif method == 'test':\n",
        "              if i in range(test_img_len):\n",
        "                img_pkl = self.root + 'rock/meta/' + str(num) + '.pkl'\n",
        "              elif i in range(test_img_len, 2*test_img_len):\n",
        "                img_pkl = self.root + 'scissors/meta/' + str(num) + '.pkl'\n",
        "              elif i in range(2*test_img_len, 3*test_img_len):\n",
        "                img_pkl = self.root + 'paper/meta/' + str(num) + '.pkl'\n",
        "\n",
        "            pkl = pandas.read_pickle(img_pkl)\n",
        "            coords_2d = pkl['coords_2d']\n",
        "            # coords_2d의 shape = 21*2\n",
        "            self.y_data.append(coords_2d)\n",
        "\n",
        "\n",
        "        length = 0\n",
        "        if method == 'train':\n",
        "          length = train_img_len\n",
        "        elif method == 'test':\n",
        "          length = test_img_len\n",
        "\n",
        "        for i in range(3):  # rock = 0, scissors = 1, paper = 2\n",
        "          for j in range(length):\n",
        "            self.z_data.append(i)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_path)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        transform1 = torchvision.transforms.ToTensor()\n",
        "        new_x_data = transform1(self.x_data[idx])\n",
        "\n",
        "        return new_x_data, self.y_data[idx], self.z_data[idx]\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjcO7nT8DwBM"
      },
      "source": [
        "class Trainer(object):\n",
        "    def __init__(self, posenet_epochs, classifier_epochs, batch_size, posenet_lr, classifier_lr):\n",
        "        self.posenet_epochs = posenet_epochs\n",
        "        self.classifier_epochs = classifier_epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.posenet_learning_rate = posenet_lr\n",
        "        self.classifier_learning_rate = classifier_lr\n",
        "        dataset = HandDataset(method='train')\n",
        "        self.weight_root = dataset.weight_root # weight_root = drive/My Drive/hand_posture_data\n",
        "        self._build_model()\n",
        "        self.root = dataset.root # self.root = drive/My Drive/hand_posture_data/train/\n",
        "        self.dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "        print(\"Training...\")\n",
        "\n",
        "    def _build_model(self):\n",
        "        # 2d pose estimator\n",
        "        poseNet = CPM2DPose()\n",
        "        self.poseNet = poseNet.to(device)\n",
        "        self.poseNet.train() # train 모드 명시\n",
        "        self.poseNet.load_state_dict(torch.load(self.weight_root+'/pretrained_weight.pth'))\n",
        "        classifier = Classifier(self.batch_size)\n",
        "        self.classifier = classifier.to(device)\n",
        "        self.classifier.train()\n",
        "\n",
        "        print('Finish build model.')\n",
        "\n",
        "    def skeleton2heatmap(self, _heatmap, keypoint_targets):\n",
        "        heatmap_gt = torch.zeros_like(_heatmap, device=_heatmap.device) \n",
        "        # _heatmap은 ground_truth heatmap만들때 dimension 같게 해주려고 참고하는 용도로만 사용\n",
        "\n",
        "        keypoint_targets = (((keypoint_targets)) // 8)\n",
        "        for i in range(keypoint_targets.shape[0]):\n",
        "            for j in range(21):\n",
        "                x = int(keypoint_targets[i, j, 0])\n",
        "                y = int(keypoint_targets[i, j, 1])\n",
        "                heatmap_gt[i, j, x, y] = 1\n",
        "\n",
        "        heatmap_gt = heatmap_gt.detach().cpu().numpy()\n",
        "        for i in range(keypoint_targets.shape[0]):\n",
        "            for j in range(21):\n",
        "                heatmap_gt[i, j, :, :] = cv2.GaussianBlur(heatmap_gt[i, j, :, :], ksize=(3, 3), sigmaX=2, sigmaY=2) * 9 / 1.1772\n",
        "        heatmap_gt = torch.FloatTensor(heatmap_gt).to(device)\n",
        "        return heatmap_gt # ground truth heatmap\n",
        "\n",
        "\n",
        "    def heatmap2skeleton(self, heatmapsPoseNet):\n",
        "        skeletons = np.zeros((heatmapsPoseNet.shape[0], heatmapsPoseNet.shape[1], 2))\n",
        "        for m in range(heatmapsPoseNet.shape[0]):\n",
        "            for i in range(heatmapsPoseNet.shape[1]):\n",
        "                u, v = np.unravel_index(np.argmax(heatmapsPoseNet[m][i]), (32, 32))\n",
        "                skeletons[m, i, 0] = u * 8\n",
        "                skeletons[m, i, 1] = v * 8\n",
        "        return skeletons\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        cpm2dpose_losses = []\n",
        "        classifier_losses = []\n",
        "        loss_func = torch.nn.MSELoss()\n",
        "        classifier_loss_func = torch.nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.SGD(self.poseNet.parameters(), self.posenet_learning_rate)\n",
        "        classifier_optimizer = torch.optim.SGD(self.classifier.parameters(), self.classifier_learning_rate)\n",
        "        #classifier_optimizer = torch.optim.Adam(self.classifier.parameters(), lr=self.learning_rate, betas=(0.9, 0.999), eps=1e-08)\n",
        "\n",
        "        for param in self.poseNet.parameters():\n",
        "          param.required_grad = True\n",
        "        \n",
        "        for epoch in tqdm.tqdm(range(self.posenet_epochs + 1)):\n",
        "            posenet_loss = 0\n",
        "            for batch_idx, samples in enumerate(self.dataloader):\n",
        "                optimizer.zero_grad()\n",
        "                x_train, y_train, z_train = samples #z_train은 semantic class정보(rock=0/scissors=1/paper=2)\n",
        "\n",
        "                heatmapsPoseNet = self.poseNet(x_train.cuda())\n",
        "                gt_heatmap = self.skeleton2heatmap(heatmapsPoseNet, y_train)\n",
        "\n",
        "                loss = loss_func(heatmapsPoseNet, gt_heatmap)\n",
        "                posenet_loss += loss.item()\n",
        "                loss.backward(retain_graph=True)  # backpropagation\n",
        "                optimizer.step() # update parameters\n",
        "\n",
        "            print('posenet training loss: ', posenet_loss)\n",
        "            cpm2dpose_losses.append(posenet_loss)\n",
        "\n",
        "            if epoch == self.posenet_epochs:\n",
        "               torch.save(self.poseNet.state_dict(), self.weight_root+'/pretrained_weight.pth')\n",
        "\n",
        "        for epoch in tqdm.tqdm(range(self.classifier_epochs + 1)):\n",
        "            classifier_loss = 0\n",
        "            for batch_idx, samples in enumerate(self.dataloader):\n",
        "                classifier_optimizer.zero_grad()\n",
        "                x_train, y_train, z_train = samples #z_train은 semantic class정보(rock=0/scissors=1/paper=2)\n",
        "\n",
        "                heatmapsPoseNet = self.poseNet(x_train.cuda())\n",
        "\n",
        "                gt_heatmap = self.skeleton2heatmap(heatmapsPoseNet, y_train.cuda()) # heatmapsPoseNet은 shape 참고하기 위해서 만든것일뿐\n",
        "                \n",
        "                pred = self.classifier(gt_heatmap)\n",
        "                \n",
        "                loss2 = classifier_loss_func(pred, z_train.cuda())\n",
        "                loss2.backward()\n",
        "                classifier_loss += loss2.item()\n",
        "                classifier_optimizer.step()\n",
        "            print('classifier training loss: ', classifier_loss)\n",
        "            classifier_losses.append(classifier_loss)\n",
        "\n",
        "            if epoch == self.classifier_epochs:\n",
        "               torch.save(self.classifier.state_dict(), self.weight_root+'/classifier_weight.pth')\n",
        "\n",
        "        \n",
        "        plt.subplot(2,1,1)\n",
        "        plt.plot(cpm2dpose_losses, color = 'r')\n",
        "        plt.subplot(2,1,2)\n",
        "        plt.plot(classifier_losses, color = 'b')\n",
        "        print('Finish training.')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekXz9CMgRlmr"
      },
      "source": [
        "class Tester(object):\n",
        "    def __init__(self, batch_size):\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        dataset = HandDataset(method='test')\n",
        "        self.CPM_weight_root = dataset.weight_root + '/pretrained_weight.pth'\n",
        "        self._build_model()\n",
        "        self.root = dataset.root # self.root = drive/My Drive/hand_posture_data/test/\n",
        "        self.dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "        self.datalen = dataset.__len__()\n",
        "        self.weight_path = dataset.weight_root\n",
        "        self.weight_path = self.weight_path+'/classifier_weight.pth' # weight_PATH = drive/My Drive/hand_posture_data/classifier_weight.pth\n",
        "        self.classifier.load_state_dict(torch.load(self.weight_path))\n",
        "\n",
        "        print(\"Testing...\")\n",
        "\n",
        "    def _build_model(self):\n",
        "        # 2d pose estimator\n",
        "        poseNet = CPM2DPose()\n",
        "        self.poseNet = poseNet.to(device)\n",
        "        self.poseNet.load_state_dict(torch.load(self.CPM_weight_root))\n",
        "        classifier = Classifier(self.batch_size)\n",
        "        self.classifier = classifier.to(device)\n",
        "\n",
        "    def skeleton2heatmap(self, _heatmap, keypoint_targets):\n",
        "        heatmap_gt = torch.zeros_like(_heatmap, device=_heatmap.device) \n",
        "\n",
        "        keypoint_targets = (((keypoint_targets)) // 8)\n",
        "        for i in range(keypoint_targets.shape[0]):\n",
        "            for j in range(21):\n",
        "                x = int(keypoint_targets[i, j, 0])\n",
        "                y = int(keypoint_targets[i, j, 1])\n",
        "                heatmap_gt[i, j, x, y] = 1\n",
        "\n",
        "        heatmap_gt = heatmap_gt.detach().cpu().numpy()\n",
        "        for i in range(keypoint_targets.shape[0]):\n",
        "            for j in range(21):\n",
        "                heatmap_gt[i, j, :, :] = cv2.GaussianBlur(heatmap_gt[i, j, :, :], ksize=(3, 3), sigmaX=2, sigmaY=2) * 9 / 1.1772\n",
        "        heatmap_gt = torch.FloatTensor(heatmap_gt).to(device)\n",
        "        return heatmap_gt \n",
        "\n",
        "    def test(self):\n",
        "        correct = 0\n",
        "        correct_2 = 0\n",
        "        total = 0\n",
        "        for batch_idx, samples in enumerate(self.dataloader): \n",
        "            x_test, y_test, z_test = samples \n",
        "            heatmapsPoseNet = self.poseNet(x_test.cuda())\n",
        "\n",
        "            pred = self.classifier(heatmapsPoseNet)\n",
        "\n",
        "            for k in range(self.batch_size):\n",
        "\n",
        "              total +=1\n",
        "              if np.argmax(pred[k].detach().cpu().numpy()) == z_test[k]:\n",
        "                correct+=1\n",
        "            \n",
        "            ################################################\n",
        "            \n",
        "            gt_heatmap = self.skeleton2heatmap(heatmapsPoseNet, y_test)\n",
        "            pred_2 = self.classifier(gt_heatmap)\n",
        "\n",
        "\n",
        "            for q in range(self.batch_size):\n",
        "              print('my prediction: ', np.argmax(pred_2[q].detach().cpu().numpy()))\n",
        "              if np.argmax(pred_2[q].detach().cpu().numpy()) == z_test[q]:\n",
        "                correct_2+=1\n",
        "            \n",
        "\n",
        "        print('Classifier Accuracy: ', correct_2/total)    \n",
        "        print('Overall Accuracy: ', correct/total)\n",
        "        self.classifier_accuracy = correct_2/total\n",
        "        self.overall_accuracy = correct/total\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEJFfWpJnVJl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "529bbfc9-9762-4e7a-950a-e4e312b0d468"
      },
      "source": [
        "def main():\n",
        "    \n",
        "    posenet_epochs = 40\n",
        "    classifier_epochs = 20\n",
        "    batchSize = 30\n",
        "    posenet_learningRate = 1e-2\n",
        "    classifier_learningRate = 1e-1\n",
        "\n",
        "    #for epochs in epoch_candidate:\n",
        "    #  for learningRate in learningRate_candidate:\n",
        "    trainer = Trainer(posenet_epochs, classifier_epochs, batchSize, posenet_learningRate, classifier_learningRate)\n",
        "    trainer.train()\n",
        "\n",
        "    tester = Tester(batchSize)\n",
        "    tester.test()\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 300/300 [02:11<00:00,  2.29it/s]\n",
            "  0%|          | 0/41 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finish build model.\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 1/41 [00:07<05:14,  7.87s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.05850501684471965\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  5%|▍         | 2/41 [00:15<05:09,  7.94s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.05849183024838567\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 3/41 [00:24<05:03,  8.00s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.05847869999706745\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|▉         | 4/41 [00:32<04:58,  8.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.05846568429842591\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 5/41 [00:40<04:53,  8.16s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.0584529647603631\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 15%|█▍        | 6/41 [00:49<04:48,  8.24s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.05844058142974973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 7/41 [00:57<04:43,  8.33s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.05842692777514458\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|█▉        | 8/41 [01:06<04:38,  8.43s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.05841526482254267\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 9/41 [01:15<04:33,  8.54s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.05840254481881857\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 10/41 [01:23<04:27,  8.61s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.05839020758867264\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 11/41 [01:32<04:18,  8.63s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.05837628152221441\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 12/41 [01:41<04:09,  8.61s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.05836417945101857\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 13/41 [01:49<04:00,  8.58s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.05835228553041816\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 14/41 [01:58<03:51,  8.56s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.05833975784480572\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 15/41 [02:06<03:42,  8.54s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.05832674540579319\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 39%|███▉      | 16/41 [02:15<03:33,  8.55s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.05831471877172589\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 41%|████▏     | 17/41 [02:23<03:25,  8.57s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.05830278620123863\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 18/41 [02:32<03:17,  8.59s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.058291126042604446\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 46%|████▋     | 19/41 [02:41<03:09,  8.60s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.05827907798811793\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 49%|████▉     | 20/41 [02:49<03:00,  8.61s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.058267311193048954\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 51%|█████     | 21/41 [02:58<02:52,  8.60s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.05825484590604901\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 54%|█████▎    | 22/41 [03:06<02:43,  8.59s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.058242416474968195\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 56%|█████▌    | 23/41 [03:15<02:34,  8.58s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.058230769354850054\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 59%|█████▊    | 24/41 [03:24<02:25,  8.58s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.05821921397000551\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 61%|██████    | 25/41 [03:32<02:17,  8.58s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.05820732098072767\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 26/41 [03:41<02:08,  8.58s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.058195951860398054\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 66%|██████▌   | 27/41 [03:49<02:00,  8.58s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.05818434525281191\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 28/41 [03:58<01:51,  8.58s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.058172913268208504\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 71%|███████   | 29/41 [04:06<01:43,  8.59s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.0581613346002996\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 30/41 [04:15<01:34,  8.59s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.05815027607604861\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 76%|███████▌  | 31/41 [04:24<01:25,  8.59s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.05813834024593234\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 32/41 [04:32<01:17,  8.59s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.058127098716795444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 33/41 [04:41<01:08,  8.60s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.058115378487855196\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 34/41 [04:49<01:00,  8.60s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.05810499284416437\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 85%|████████▌ | 35/41 [04:58<00:51,  8.60s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.058093268889933825\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 88%|████████▊ | 36/41 [05:07<00:42,  8.60s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.058081917464733124\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 37/41 [05:15<00:34,  8.60s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.058070498052984476\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 93%|█████████▎| 38/41 [05:24<00:25,  8.60s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.05806050868704915\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 95%|█████████▌| 39/41 [05:32<00:17,  8.60s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.05805013608187437\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 98%|█████████▊| 40/41 [05:41<00:08,  8.60s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "posenet training loss:  0.05803913902491331\n",
            "posenet training loss:  0.058027124498039484\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 41/41 [05:51<00:00,  8.58s/it]\n",
            "  0%|          | 0/21 [00:00<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-60a33459ff30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-60a33459ff30>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#  for learningRate in learningRate_candidate:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposenet_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposenet_learningRate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_learningRate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtester\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTester\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-1a056468ccda>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;31m#z_train은 semantic class정보(rock=0/scissors=1/paper=2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mheatmapsPoseNet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposeNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mgt_heatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskeleton2heatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheatmapsPoseNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# heatmapsPoseNet은 shape 참고하기 위해서 만든것일뿐\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-39408af3946c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    419\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 420\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 240.00 MiB (GPU 0; 14.73 GiB total capacity; 13.21 GiB already allocated; 159.88 MiB free; 13.64 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    }
  ]
}